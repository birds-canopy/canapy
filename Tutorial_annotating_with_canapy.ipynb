{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "# Annotating data with canapy - tutorial"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Canapy you can train an AI model to annotate bird songs. This tutorial shows you how to use this trained model to annotate data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from canapy.corpus import Corpus\n",
    "from canapy.annotator import get_annotator\n",
    "from canapy.config import default_config\n",
    "from canapy import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T08:18:29.957588414Z",
     "start_time": "2023-07-21T08:18:28.389999421Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Annotators\n",
    "\n",
    "First, you have to create an Annotator object, there is three types possible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T08:18:30.016946274Z",
     "start_time": "2023-07-21T08:18:29.999853748Z"
    }
   },
   "outputs": [],
   "source": [
    "syn_annotator = get_annotator(\"syn-esn\")(default_config, \"./tuto/spec\")\n",
    "nsyn_annotator = get_annotator(\"nsyn-esn\")(default_config, \"./tuto/spec\")\n",
    "ensemble_annotator = get_annotator(\"ensemble\")(default_config, \"./tuto/spec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has been given to all of them the `default_config`, but you can create your own configuration and applied it on your annotators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Data\n",
    "\n",
    "Then you need to import an annotated corpus to train annotators, and a corpus that you want to annotate :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "corpus_annotated_songs = Corpus.from_directory(audio_directory=\"./tuto/annotated_songs\", annots_directory=\"./tuto/annotated_songs\")\n",
    "\n",
    "corpus_non_annotated_songs = Corpus.from_directory(audio_directory=\"./tuto/non_annotated_songs\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T08:18:30.459438804Z",
     "start_time": "2023-07-21T08:18:30.000887885Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example, the `/tuto/annotated_songs` directory contains some .wav audio files and a .csv annotation files for each whereas `/tuto/non_annotated_songs` directory contains only .wav audio files, one per song, ready to be annotated.\n",
    "\n",
    "The Corpus object stores the dataset in the form of a Pandas Dataframe, in the last case only paths to audio files, but can also store annotations as in the first case."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Annotators\n",
    "\n",
    "Every annotator needs to be trained before any manipulation :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:canapy:Applying audio transform compute_mfcc on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'output_directory': PosixPath('tuto/spec'), 'resource_name': 'syn_mfcc', 'redo': False}).\n",
      "INFO:canapy:Applying corpus transform sort_annotations on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'redo': False}).\n",
      "INFO:canapy:Applying corpus transform merge_labels on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'redo': False}).\n",
      "INFO:canapy:Applying corpus transform sort_annotations on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'redo': False}).\n",
      "INFO:canapy:Applying corpus transform tag_silences on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'redo': False}).\n",
      "INFO:canapy:Applying corpus transform sort_annotations on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'redo': False}).\n",
      "INFO:canapy:Applying corpus transform remove_short_labels on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'redo': False}).\n",
      "INFO:canapy:Applying corpus transform sort_annotations on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'redo': False}).\n",
      "INFO:canapy:Applying training data tranform split_train_test on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'resource_name': None, 'redo': False}).\n",
      "INFO:canapy:Min. number of sequences to train over all classes : 12\n",
      "INFO:canapy:Final repartition of data - \n",
      "Train : 36 (688 labels - 1235.461 s - 875.285 s (w/o silence)\n",
      "Test: 9 (160 labels) - 271.995 s - 204.284 s (w/o silence)\n",
      "INFO:canapy:Applying training data tranform encode_labels on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'resource_name': None, 'redo': False}).\n",
      "WARNING:canapy:Found inconsistent sequence length: audio tuto/annotated_songs/51-151_Box3_April_03_2014_53906971.wav was converted to 4532 timesteps but last annotation is at timestep 4536. Annotation will be trimmed.\n",
      "WARNING:canapy:Found inconsistent sequence length: audio tuto/annotated_songs/57-157_Box3_April_03_2014_54243582.wav was converted to 4533 timesteps but last annotation is at timestep 4534. Annotation will be trimmed.\n",
      "WARNING:canapy:Found inconsistent sequence length: audio tuto/annotated_songs/59-159_Box3_April_03_2014_54303053.wav was converted to 4532 timesteps but last annotation is at timestep 4534. Annotation will be trimmed.\n",
      "WARNING:canapy:Found inconsistent sequence length: audio tuto/annotated_songs/68-168_Box3_April_03_2014_57243708.wav was converted to 4533 timesteps but last annotation is at timestep 4534. Annotation will be trimmed.\n",
      "WARNING:canapy:Found inconsistent sequence length: audio tuto/annotated_songs/77-177_Box3_April_03_2014_66496453.wav was converted to 4533 timesteps but last annotation is at timestep 4536. Annotation will be trimmed.\n",
      "WARNING:canapy:Found inconsistent sequence length: audio tuto/annotated_songs/79-179_Box3_April_03_2014_66553276.wav was converted to 4533 timesteps but last annotation is at timestep 4535. Annotation will be trimmed.\n",
      "WARNING:canapy:Found inconsistent sequence length: audio tuto/annotated_songs/81-181_Box3_April_03_2014_66634568.wav was converted to 4536 timesteps but last annotation is at timestep 4540. Annotation will be trimmed.\n",
      "WARNING:canapy:Found inconsistent sequence length: audio tuto/annotated_songs/83-183_Box3_April_03_2014_66709365.wav was converted to 4528 timesteps but last annotation is at timestep 4530. Annotation will be trimmed.\n",
      "WARNING:canapy:Found inconsistent sequence length: audio tuto/annotated_songs/85-185_Box3_April_03_2014_66782748.wav was converted to 4527 timesteps but last annotation is at timestep 4529. Annotation will be trimmed.\n",
      "Running ESN-0: 100%|██████████| 36/36 [00:10<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting node ESN-0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:canapy:Applying audio transform compute_mfcc on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'output_directory': PosixPath('tuto/spec'), 'resource_name': 'syn_mfcc', 'redo': False}).\n",
      "INFO:canapy:Applying corpus transform sort_annotations on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'redo': False}).\n",
      "INFO:canapy:Applying corpus transform merge_labels on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'redo': False}).\n",
      "INFO:canapy:Applying corpus transform sort_annotations on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'redo': False}).\n",
      "INFO:canapy:Applying corpus transform tag_silences on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'redo': False}).\n",
      "INFO:canapy:Applying corpus transform sort_annotations on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'redo': False}).\n",
      "INFO:canapy:Applying corpus transform remove_short_labels on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'redo': False}).\n",
      "INFO:canapy:Applying corpus transform sort_annotations on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'redo': False}).\n",
      "INFO:canapy:Applying training data tranform split_train_test on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'resource_name': None, 'redo': False}).\n",
      "INFO:canapy:Min. number of sequences to train over all classes : 12\n",
      "INFO:canapy:Final repartition of data - \n",
      "Train : 36 (688 labels - 1235.461 s - 875.285 s (w/o silence)\n",
      "Test: 9 (160 labels) - 271.995 s - 204.284 s (w/o silence)\n",
      "INFO:canapy:Applying training data tranform encode_labels on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'resource_name': None, 'redo': False}).\n",
      "INFO:canapy:Applying training data tranform balance_labels_duration on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'resource_name': 'balanced_dataset', 'redo': False}).\n",
      "/home/vincent/Documents/Travail/Stage_L3/canapy-reborn/canapy/transforms/nsynesn.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subsampled[\"augmented\"] = subsampled.index.duplicated(keep=\"first\")\n",
      "INFO:canapy:Applying training data transform compute_mfcc_for_balanced_dataset on ((<Corpus at (audio) tuto/annotated_songs | (annots) tuto/annotated_songs.>,), {'resource_name': 'mfcc_dataset', 'redo': False}).\n",
      "/home/vincent/.cache/pypoetry/virtualenvs/canapy-reborn-Z9JxJmaD-py3.10/lib/python3.10/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1808\n",
      "  warnings.warn(\n",
      "/home/vincent/.cache/pypoetry/virtualenvs/canapy-reborn-Z9JxJmaD-py3.10/lib/python3.10/site-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1455\n",
      "  warnings.warn(\n",
      "Running ESN-1: 100%|██████████| 1865/1865 [00:32<00:00, 57.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting node ESN-1...\n"
     ]
    },
    {
     "data": {
      "text/plain": "<canapy.annotator.ensemble.Ensemble at 0x7fc516cfc970>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_annotator.fit(corpus_annotated_songs)\n",
    "nsyn_annotator.fit(corpus_annotated_songs)\n",
    "ensemble_annotator.fit(corpus_annotated_songs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T08:20:13.694287862Z",
     "start_time": "2023-07-21T08:18:30.462173310Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Annotate New Songs\n",
    "\n",
    "Syntaxic (`syn-esn`) and NonSyntaxic (`nsyn-esn`) Annotators annotate new songs with the following lines :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:canapy:Applying audio transform compute_mfcc on ((<Corpus at (audio) tuto/non_annotated_songs | (annots) None.>,), {'output_directory': PosixPath('tuto/spec'), 'resource_name': 'syn_mfcc', 'redo': False}).\n",
      "INFO:canapy:Applying audio transform ls_audio_dir on ((<Corpus at (audio) tuto/non_annotated_songs | (annots) None.>,), {}).\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m corpus_syn_predicted \u001B[38;5;241m=\u001B[39m \u001B[43msyn_annotator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcorpus_non_annotated_songs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m corpus_nsyn_predicted \u001B[38;5;241m=\u001B[39m nsyn_annotator\u001B[38;5;241m.\u001B[39mpredict(corpus_non_annotated_songs)\n",
      "File \u001B[0;32m~/Documents/Travail/Stage_L3/canapy-reborn/canapy/annotator/synannotator.py:186\u001B[0m, in \u001B[0;36mSynAnnotator.predict\u001B[0;34m(self, corpus, return_raw, redo_transforms)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, corpus, return_raw\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, redo_transforms\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    145\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;124;03m    Predict annotations for the given corpus.\u001B[39;00m\n\u001B[1;32m    147\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    184\u001B[0m \n\u001B[1;32m    185\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 186\u001B[0m     notated_paths, cls_preds, raw_preds \u001B[38;5;241m=\u001B[39m \u001B[43mpredict_with_esn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcorpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_raw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_raw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredo_transforms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mredo_transforms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    193\u001B[0m     config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\n\u001B[1;32m    195\u001B[0m     hop_length \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mtransforms\u001B[38;5;241m.\u001B[39maudio\u001B[38;5;241m.\u001B[39mhop_length\n",
      "File \u001B[0;32m~/Documents/Travail/Stage_L3/canapy-reborn/canapy/annotator/commons/esn.py:78\u001B[0m, in \u001B[0;36mpredict_with_esn\u001B[0;34m(annotator, corpus, return_raw, redo_transforms)\u001B[0m\n\u001B[1;32m     70\u001B[0m corpus \u001B[38;5;241m=\u001B[39m annotator\u001B[38;5;241m.\u001B[39mtransforms(\n\u001B[1;32m     71\u001B[0m     corpus,\n\u001B[1;32m     72\u001B[0m     purpose\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mannotation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     73\u001B[0m     output_directory\u001B[38;5;241m=\u001B[39mannotator\u001B[38;5;241m.\u001B[39mspec_directory,\n\u001B[1;32m     74\u001B[0m )\n\u001B[1;32m     76\u001B[0m notated_paths, mfccs \u001B[38;5;241m=\u001B[39m load_mfccs_for_annotation(corpus)\n\u001B[0;32m---> 78\u001B[0m raw_preds \u001B[38;5;241m=\u001B[39m \u001B[43mannotator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrpy_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmfccs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(raw_preds, np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;129;01mand\u001B[39;00m raw_preds\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[1;32m     81\u001B[0m     raw_preds \u001B[38;5;241m=\u001B[39m [raw_preds]\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/canapy-reborn-Z9JxJmaD-py3.10/lib/python3.10/site-packages/reservoirpy/nodes/esn.py:307\u001B[0m, in \u001B[0;36mESN.run\u001B[0;34m(self, X, forced_feedbacks, from_state, stateful, reset, shift_fb, return_states)\u001B[0m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun\u001B[39m(\n\u001B[1;32m    295\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    296\u001B[0m     X\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    302\u001B[0m     return_states\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    303\u001B[0m ):\n\u001B[1;32m    305\u001B[0m     X, forced_feedbacks \u001B[38;5;241m=\u001B[39m to_data_mapping(\u001B[38;5;28mself\u001B[39m, X, forced_feedbacks)\n\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initialize_on_sequence(\u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m, forced_feedbacks[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    309\u001B[0m     backend \u001B[38;5;241m=\u001B[39m get_joblib_backend(workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworkers, backend\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackend)\n\u001B[1;32m    311\u001B[0m     seq \u001B[38;5;241m=\u001B[39m progress(X, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRunning \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "corpus_syn_predicted = syn_annotator.predict(corpus_non_annotated_songs)\n",
    "corpus_nsyn_predicted = nsyn_annotator.predict(corpus_non_annotated_songs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T08:20:24.060785514Z",
     "start_time": "2023-07-21T08:20:13.694850976Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The case of ensemble is a little bit more complicated, because you need to predict some corpus using `return_raw=True`, and then predict with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus_syn_predicted_raw = syn_annotator.predict(corpus_non_annotated_songs, return_raw=True)\n",
    "corpus_nsyn_predicted_raw = nsyn_annotator.predict(corpus_non_annotated_songs, return_raw=True)\n",
    "\n",
    "corpus_ensemble_predicted = ensemble_annotator.predict([corpus_syn_predicted, corpus_nsyn_predicted_raw])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note : if you planned to predict a corpus with the three types of annotators, no need to predict two times a corpus with syn and nsyn annotators (with and without return_raw) because return_raw just add data on the same corpus that is predicted when it is false."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Annotations\n",
    "\n",
    "Now that your annotators have made some annotions, you can store it on the disk :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus_syn_predicted.to_disk(\"/tuto/results/syn\")\n",
    "corpus_nsyn_predicted.to_disk(\"/tuto/results/nsyn\")\n",
    "corpus_ensemble_predicted.to_disk(\"/tuto/results/ensemble\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You have now new annotation files !"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyze Annotators' Performances\n",
    "\n",
    "You have annotated new songs, but how good the predictions are ?\n",
    "To figure it out you should use `metrics` to compare annotations that you have made and those made by ESNs.\n",
    "\n",
    "We will analyze only a Syntactic Annotator but the method remains the same for all of them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corpus_annotated_songs_predicted = syn_annotator.predict(corpus_annotated_songs)\n",
    "\n",
    "print(metrics.sklearn_confusion_matrix(corpus_annotated_songs, corpus_annotated_songs_predicted))\n",
    "\n",
    "print(metrics.sklearn_classification_report(corpus_annotated_songs, corpus_annotated_songs_predicted))\n",
    "\n",
    "print(metrics.segment_error_rate(corpus_annotated_songs, corpus_annotated_songs_predicted))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
